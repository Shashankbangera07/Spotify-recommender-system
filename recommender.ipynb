{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will build a content-based recommendation system on the previously saved .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spotipy in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (from spotipy) (2.31.0)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (from spotipy) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages (from requests>=2.25.0->spotipy) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install spotipy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cdist\n",
    "cid = 'cdb0a1aa1fc24842b9d98603fab657be'\n",
    "secret = 'e421b4cb445b45dd8ea9635ba9892c22'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager\n",
    "=\n",
    "client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fourtet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function uses Spotipy to find any track and return its metadata and audio features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_song(name, artist):\n",
    "\n",
    "    # Initialize an empty dictionary to store features and values\n",
    "    song_data = defaultdict()\n",
    "    \n",
    "    # Using Spotipy search function for track and artist, returning None if cannot be found in Spotify\n",
    "    results = sp.search(q= 'track: {} artist: {}'.format(name,\n",
    "                                                       artist), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    # Isolating track information and ID from results\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    \n",
    "    # Obtaining audio features\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "    \n",
    "    # Preparing columns and converting to DataFrame\n",
    "    song_data['name'] = [name]\n",
    "    song_data['artist'] = [artist]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "    \n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "    \n",
    "    return pd.DataFrame(song_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call a function to return this information from a dataset and revert to our previous function if the song is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_data(song, spotify_data):\n",
    "\n",
    "    # Function will attempt to find ID track name and artist from dataset to return track data\n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['track_name'] == song['name']) \n",
    "                                & (spotify_data['artist_name'] == song['artist'])].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song(song['name'], song['artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a list of multiple songs, we can calculate the mean vector of its audio features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(song_list, spotify_data):\n",
    "\n",
    "    #Initialize empty list to store vectors\n",
    "    song_vectors = []\n",
    "\n",
    "    # Identify audio features columns\n",
    "    number_cols = ['valence', 'acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo']\n",
    "\n",
    "    # Append list of values to list\n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print('Warning: {} not found in Spotify or database'.format(song['name']))\n",
    "            continue\n",
    "        song_vector = song_data[number_cols].values\n",
    "        song_vectors.append(song_vector)  \n",
    "    \n",
    "    # Convert to single array and return mean\n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to build our recommender. This function will take in a list of songs and return n recommendations as set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(song_list, spotify_data, n_songs=10):\n",
    "\n",
    "    # Establishing metadata and numerical columns\n",
    "    metadata_cols = ['track_name', 'artist_name']\n",
    "    number_cols = ['valence', 'acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo']\n",
    "    \n",
    "    # Getting mean vector\n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "    \n",
    "    # Dropping extra columns\n",
    "    spotify_data = spotify_data.drop(['popularity', 'Unnamed: 0'], axis=1)\n",
    "    \n",
    "    # Using KMeans to cluster data, fitting and adding labels to dataset\n",
    "    X = spotify_data.select_dtypes(np.number)\n",
    "    cluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=3))])\n",
    "    cluster_pipeline.fit(X)\n",
    "    cluster_labels = cluster_pipeline.predict(X)\n",
    "    spotify_data['cluster'] = cluster_labels\n",
    "    \n",
    "    # Scaling and transforming numerical columns of data and reshaped song center\n",
    "    scaler = cluster_pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(spotify_data[number_cols])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "    \n",
    "    # Computing cosine distance on transformed arrays\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    \n",
    "    # Return sorted list of top n indices \n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    # Converting to DataFrame and returning track and artist name\n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    df_recs = pd.DataFrame(rec_songs[metadata_cols])\n",
    "    return df_recs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashankbangera/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m song_list \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mCardigan\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39martist\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mTaylor Swift\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mLove Ridden\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39martist\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mFiona Apple\u001b[39m\u001b[39m'\u001b[39m}]\n\u001b[0;32m----> 2\u001b[0m rec_df \u001b[39m=\u001b[39m recommend_songs(song_list, df)\n\u001b[1;32m      3\u001b[0m rec_df\n",
      "Cell \u001b[0;32mIn[32], line 22\u001b[0m, in \u001b[0;36mrecommend_songs\u001b[0;34m(song_list, spotify_data, n_songs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Scaling and transforming numerical columns of data and reshaped song center\u001b[39;00m\n\u001b[1;32m     21\u001b[0m scaler \u001b[39m=\u001b[39m cluster_pipeline\u001b[39m.\u001b[39msteps[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m scaled_data \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(spotify_data[number_cols])\n\u001b[1;32m     23\u001b[0m scaled_song_center \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(song_center\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m \u001b[39m# Computing cosine distance on transformed arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1001\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1003\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m-> 1004\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1005\u001b[0m     X,\n\u001b[1;32m   1006\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1007\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1008\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1009\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m   1010\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1011\u001b[0m )\n\u001b[1;32m   1013\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m   1014\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/spotify_recsys/lib/python3.11/site-packages/sklearn/base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    502\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 506\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "song_list = [{'name': 'Cardigan', 'artist': 'Taylor Swift','name': 'Love Ridden', 'artist': 'Fiona Apple'}]\n",
    "rec_df = recommend_songs(song_list, df)\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to deploy our recommendation system in Streamlit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
